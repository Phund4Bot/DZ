{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Phund4Bot/DZ/blob/main/BD6laba.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGPGrQWcWppe"
      },
      "source": [
        "<h>Spark ML <h>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install pyspark"
      ],
      "metadata": {
        "id": "K6zvamDPWsol",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6fda603-a68e-4a87-8516-6a84a1337f5c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.1.tar.gz (317.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.0/317.0 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.1-py2.py3-none-any.whl size=317488491 sha256=c183af99655c1ef34ed08571c08daa4bd0e6c430d058e98c9599e5dbe8210758\n",
            "  Stored in directory: /root/.cache/pip/wheels/80/1d/60/2c256ed38dddce2fdd93be545214a63e02fbd8d74fb0b7f3a6\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "_dtoNK95Wppm"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.feature import StringIndexer # Выполнение энкодинга\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "_iu4H5TZWppq"
      },
      "outputs": [],
      "source": [
        "spark = SparkSession.builder.appName(\"PySparkTitanikJob\").getOrCreate()\n",
        "\n",
        "#Создаём Spark сессию"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "BlfwVjSsWpps",
        "outputId": "1a96a474-4c1f-45e1-dbab-219d8bc76e34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7cbdf3ccbdf0>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://cbdd87d68ba7:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>PySparkTitanikJob</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "spark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "KFVvaBVzWppt"
      },
      "outputs": [],
      "source": [
        "titanic_df = spark.read.parquet('train.parquet')\n",
        "#С помощью метода spark.read.parquet прочитайте датасет в переменную titanic_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "kXPFJ9DCWppu",
        "outputId": "fa23b86b-54f1-4d8f-ff81-0a03c3676179",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+------+------+----+-----+-----+-------+--------+-----------+-----+\n",
            "|Survived|Pclass|   Sex| Age|SibSp|Parch|   Fare|Embarked|Family_Size|Alone|\n",
            "+--------+------+------+----+-----+-----+-------+--------+-----------+-----+\n",
            "|       0|     3|  male|22.0|    1|    0|   7.25|       S|          1|    0|\n",
            "|       1|     1|female|38.0|    1|    0|71.2833|       C|          1|    0|\n",
            "|       1|     3|female|26.0|    0|    0|  7.925|       S|          0|    1|\n",
            "|       1|     1|female|35.0|    1|    0|   53.1|       S|          1|    0|\n",
            "|       0|     3|  male|35.0|    0|    0|   8.05|       S|          0|    1|\n",
            "|       0|     3|  male|30.0|    0|    0| 8.4583|       Q|          0|    1|\n",
            "|       0|     1|  male|54.0|    0|    0|51.8625|       S|          0|    1|\n",
            "|       0|     3|  male| 2.0|    3|    1| 21.075|       S|          4|    0|\n",
            "|       1|     3|female|27.0|    0|    2|11.1333|       S|          2|    0|\n",
            "|       1|     2|female|14.0|    1|    0|30.0708|       C|          1|    0|\n",
            "|       1|     3|female| 4.0|    1|    1|   16.7|       S|          2|    0|\n",
            "|       1|     1|female|58.0|    0|    0|  26.55|       S|          0|    1|\n",
            "|       0|     3|  male|20.0|    0|    0|   8.05|       S|          0|    1|\n",
            "|       0|     3|  male|39.0|    1|    5| 31.275|       S|          6|    0|\n",
            "|       0|     3|female|14.0|    0|    0| 7.8542|       S|          0|    1|\n",
            "|       1|     2|female|55.0|    0|    0|   16.0|       S|          0|    1|\n",
            "|       0|     3|  male| 2.0|    4|    1| 29.125|       Q|          5|    0|\n",
            "|       1|     2|  male|30.0|    0|    0|   13.0|       S|          0|    1|\n",
            "|       0|     3|female|31.0|    1|    0|   18.0|       S|          1|    0|\n",
            "|       1|     3|female|30.0|    0|    0|  7.225|       C|          0|    1|\n",
            "+--------+------+------+----+-----+-----+-------+--------+-----------+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "titanic_df.show()\n",
        "#Выведите значения датафрейма с помощью метода show()\n",
        "\n",
        "# Мы будем классифицировать, погибнет или выживет пассажир Титаника\n",
        "# Целевой признак - Survived\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "DsnviqkqWppu"
      },
      "outputs": [],
      "source": [
        "# Поработаем с категориальными признаками.\n",
        "\n",
        "#Функция StringIndexer индексирует (энкодит) строки\n",
        "#Концепция, лежащая в основе индексирования строк, очень интуитивно понятна.\n",
        "#Мы просто заменяем каждую категорию номером.\n",
        "\n",
        "sex_index = StringIndexer(inputCol='Sex', outputCol=\"Sex_index\")  #StringIndexer - это Estimator, который нам формирует Transformer для преобразования данных\n",
        "embarked_index = StringIndexer(inputCol='Embarked', outputCol=\"Embarked_index\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "7AEBrRe-Wppv"
      },
      "outputs": [],
      "source": [
        "# теперь применим новые столбцы к нашему датафрейму. Сначала обращаемся ним и выполняем операцию fit на нашем датафрейме.\n",
        "#После чего мы получим функцию трансформер и сможем вызвать ф-ию transform для того, чтобы выполнить преобразование наших данных\n",
        "\n",
        "titanic_df = sex_index.fit(titanic_df).transform(titanic_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BTy3mLzRWppw"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "NpPWgq2RWppw"
      },
      "outputs": [],
      "source": [
        "# Сделайте преобразование для embarked_index\n",
        "titanic_df = embarked_index.fit(titanic_df).transform(titanic_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "8i4vhT28Wppx",
        "outputId": "844f552a-e2aa-4cb8-f527-d675d575cac0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+------+------+----+-----+-----+-------+--------+-----------+-----+---------+--------------+\n",
            "|Survived|Pclass|   Sex| Age|SibSp|Parch|   Fare|Embarked|Family_Size|Alone|Sex_index|Embarked_index|\n",
            "+--------+------+------+----+-----+-----+-------+--------+-----------+-----+---------+--------------+\n",
            "|       0|     3|  male|22.0|    1|    0|   7.25|       S|          1|    0|      0.0|           0.0|\n",
            "|       1|     1|female|38.0|    1|    0|71.2833|       C|          1|    0|      1.0|           1.0|\n",
            "|       1|     3|female|26.0|    0|    0|  7.925|       S|          0|    1|      1.0|           0.0|\n",
            "|       1|     1|female|35.0|    1|    0|   53.1|       S|          1|    0|      1.0|           0.0|\n",
            "|       0|     3|  male|35.0|    0|    0|   8.05|       S|          0|    1|      0.0|           0.0|\n",
            "|       0|     3|  male|30.0|    0|    0| 8.4583|       Q|          0|    1|      0.0|           2.0|\n",
            "|       0|     1|  male|54.0|    0|    0|51.8625|       S|          0|    1|      0.0|           0.0|\n",
            "|       0|     3|  male| 2.0|    3|    1| 21.075|       S|          4|    0|      0.0|           0.0|\n",
            "|       1|     3|female|27.0|    0|    2|11.1333|       S|          2|    0|      1.0|           0.0|\n",
            "|       1|     2|female|14.0|    1|    0|30.0708|       C|          1|    0|      1.0|           1.0|\n",
            "|       1|     3|female| 4.0|    1|    1|   16.7|       S|          2|    0|      1.0|           0.0|\n",
            "|       1|     1|female|58.0|    0|    0|  26.55|       S|          0|    1|      1.0|           0.0|\n",
            "|       0|     3|  male|20.0|    0|    0|   8.05|       S|          0|    1|      0.0|           0.0|\n",
            "|       0|     3|  male|39.0|    1|    5| 31.275|       S|          6|    0|      0.0|           0.0|\n",
            "|       0|     3|female|14.0|    0|    0| 7.8542|       S|          0|    1|      1.0|           0.0|\n",
            "|       1|     2|female|55.0|    0|    0|   16.0|       S|          0|    1|      1.0|           0.0|\n",
            "|       0|     3|  male| 2.0|    4|    1| 29.125|       Q|          5|    0|      0.0|           2.0|\n",
            "|       1|     2|  male|30.0|    0|    0|   13.0|       S|          0|    1|      0.0|           0.0|\n",
            "|       0|     3|female|31.0|    1|    0|   18.0|       S|          1|    0|      1.0|           0.0|\n",
            "|       1|     3|female|30.0|    0|    0|  7.225|       C|          0|    1|      1.0|           1.0|\n",
            "+--------+------+------+----+-----+-----+-------+--------+-----------+-----+---------+--------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "titanic_df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Fd40FCWpWppx"
      },
      "outputs": [],
      "source": [
        "# Наш dataframe готов к тому, чтобы применить к нему модель. Но мы хотим сначала выполнить векторизацию, чтобы данные можно было применять в моделе.\n",
        "# Формируем список признаков, которые мы будем использовать, как фичи.\n",
        "features = ['Pclass', 'Age', 'SibSp', 'SibSp', 'Parch', 'Fare', 'Alone', 'Sex_index', 'Embarked_index']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "eUN58Y7VWppy"
      },
      "outputs": [],
      "source": [
        "feature = VectorAssembler(inputCols=features, outputCol=\"features\")\n",
        "#VectorAssembler объединяет заданный список столбцов в один векторный столбец.\n",
        "# Является, пожалуй, самым важным векторным преобразователем в PySpark,\n",
        "# поскольку модели машинного обучения требуют на вход векторы.\n",
        "\n",
        "# VectorAssembler - трансформер, соответственно, вызываем метод transform  и применяем его к нашему датафрейму.\n",
        "feature_vector= feature.transform(titanic_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "NrffFCilWppy",
        "outputId": "6ff47049-e51b-4f5b-d56c-777645cf1f9e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+------+------+----+-----+-----+-------+--------+-----------+-----+---------+--------------+--------------------+\n",
            "|Survived|Pclass|   Sex| Age|SibSp|Parch|   Fare|Embarked|Family_Size|Alone|Sex_index|Embarked_index|            features|\n",
            "+--------+------+------+----+-----+-----+-------+--------+-----------+-----+---------+--------------+--------------------+\n",
            "|       0|     3|  male|22.0|    1|    0|   7.25|       S|          1|    0|      0.0|           0.0|[3.0,22.0,1.0,1.0...|\n",
            "|       1|     1|female|38.0|    1|    0|71.2833|       C|          1|    0|      1.0|           1.0|[1.0,38.0,1.0,1.0...|\n",
            "|       1|     3|female|26.0|    0|    0|  7.925|       S|          0|    1|      1.0|           0.0|[3.0,26.0,0.0,0.0...|\n",
            "|       1|     1|female|35.0|    1|    0|   53.1|       S|          1|    0|      1.0|           0.0|[1.0,35.0,1.0,1.0...|\n",
            "|       0|     3|  male|35.0|    0|    0|   8.05|       S|          0|    1|      0.0|           0.0|(9,[0,1,5,6],[3.0...|\n",
            "+--------+------+------+----+-----+-----+-------+--------+-----------+-----+---------+--------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "feature_vector.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "xCbGOldIWppz"
      },
      "outputs": [],
      "source": [
        "(training_data, test_data) = feature_vector.randomSplit([0.8, 0.2],seed = 42)\n",
        "#Формируем тренировочный и тестовый датасет. 80% данных в тренировочный, остальные - в тестовый. Seed - параметр случайности"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Cw0SY5yoWppz",
        "outputId": "48161d7c-5bf1-4da7-95da-cd684640095c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+------+------+----+-----+-----+------+--------+-----------+-----+---------+--------------+--------------------+\n",
            "|Survived|Pclass|   Sex| Age|SibSp|Parch|  Fare|Embarked|Family_Size|Alone|Sex_index|Embarked_index|            features|\n",
            "+--------+------+------+----+-----+-----+------+--------+-----------+-----+---------+--------------+--------------------+\n",
            "|       0|     1|female| 2.0|    1|    2|151.55|       S|          3|    0|      1.0|           0.0|[1.0,2.0,1.0,1.0,...|\n",
            "|       0|     1|female|25.0|    1|    2|151.55|       S|          3|    0|      1.0|           0.0|[1.0,25.0,1.0,1.0...|\n",
            "|       0|     1|  male|18.0|    1|    0| 108.9|       C|          1|    0|      0.0|           1.0|[1.0,18.0,1.0,1.0...|\n",
            "|       0|     1|  male|19.0|    1|    0|  53.1|       S|          1|    0|      0.0|           0.0|[1.0,19.0,1.0,1.0...|\n",
            "|       0|     1|  male|19.0|    3|    2| 263.0|       S|          5|    0|      0.0|           0.0|[1.0,19.0,3.0,3.0...|\n",
            "+--------+------+------+----+-----+-----+------+--------+-----------+-----+---------+--------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "training_data.show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ADZ2UFiGWpp0"
      },
      "source": [
        "# ML models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "gaK7oR_wWpp0"
      },
      "source": [
        "# LogisticRegression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "bQhjNNJrWpp0"
      },
      "outputs": [],
      "source": [
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"Survived\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "\n",
        "#Сначала создаем объект evaluator. Указываем целевую колонку обучения модели - labelCol. далее указываем\n",
        "# имя колонки, где будет лежать предсказанное значение  - predictionCol. И указываем метрику для оценки качества модели."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "IxqKG_RYWpp1",
        "outputId": "11b6ab80-a35e-456c-fecc-68abf40a574a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+--------+--------------------+\n",
            "|prediction|Survived|            features|\n",
            "+----------+--------+--------------------+\n",
            "|       1.0|       0|[1.0,50.0,0.0,0.0...|\n",
            "|       1.0|       0|(9,[0,1,4,5],[1.0...|\n",
            "|       1.0|       0|[1.0,24.0,0.0,0.0...|\n",
            "|       0.0|       0|(9,[0,1,5,6],[1.0...|\n",
            "|       0.0|       0|(9,[0,1,5,6],[1.0...|\n",
            "+----------+--------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.ml.classification import LogisticRegression\n",
        "lr = LogisticRegression(labelCol=\"Survived\", featuresCol=\"features\") # labelCol=\"Survived\" - целевая фича,  featuresCol=\"features\" - фичи, которые\n",
        "#используются для предсказания занчения целевой колонки\n",
        "\n",
        "lrModel = lr.fit(training_data) # получаем обученную модель.\n",
        "\n",
        "lr_prediction = lrModel.transform(test_data) # применяем модель на данных, получаем предсказание\n",
        "lr_prediction.select(\"prediction\", \"Survived\", \"features\").show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "O_cPn1a3Wpp2",
        "outputId": "d13b5dbe-c9c1-4e1c-b92a-a5d200990a61",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogisticRegression [Accuracy] = 0.813793\n",
            "LogisticRegression [Error] = 0.186207 \n"
          ]
        }
      ],
      "source": [
        "# Применяем оценщик (evaluator), чтобы узнать точность модели.\n",
        "lr_accuracy = evaluator.evaluate(lr_prediction)\n",
        "print(\"LogisticRegression [Accuracy] = %g\"% (lr_accuracy))\n",
        "print(\"LogisticRegression [Error] = %g \" % (1.0 - lr_accuracy))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "-WVOeNlrWpp3"
      },
      "source": [
        "# DecisionTreeClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "c_4Z1jFuWpp3",
        "outputId": "b7417662-b8df-4c86-bf38-43b8eed25444",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+--------+--------------------+\n",
            "|prediction|Survived|            features|\n",
            "+----------+--------+--------------------+\n",
            "|       1.0|       0|[1.0,50.0,0.0,0.0...|\n",
            "|       0.0|       0|(9,[0,1,4,5],[1.0...|\n",
            "|       0.0|       0|[1.0,24.0,0.0,0.0...|\n",
            "|       0.0|       0|(9,[0,1,5,6],[1.0...|\n",
            "|       0.0|       0|(9,[0,1,5,6],[1.0...|\n",
            "+----------+--------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.ml.classification import DecisionTreeClassifier\n",
        "dt = DecisionTreeClassifier(labelCol=\"Survived\", featuresCol=\"features\")\n",
        "dt_model = dt.fit(training_data)\n",
        "dt_prediction = dt_model.transform(test_data)\n",
        "\n",
        "dt_prediction.select(\"prediction\", \"Survived\", \"features\").show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "WCbA7mb8Wpp4",
        "outputId": "0f0d4f91-e6b1-4eab-dd13-8c5ae6b1d532",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DecisionTreeClassifier [Accuracy] = 0.82069\n",
            "DecisionTreeClassifier [Error] = 0.17931 \n"
          ]
        }
      ],
      "source": [
        "dt_accuracy = evaluator.evaluate(dt_prediction)\n",
        "print(\"DecisionTreeClassifier [Accuracy] = %g\"% (dt_accuracy))\n",
        "print(\"DecisionTreeClassifier [Error] = %g \" % (1.0 - dt_accuracy))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "ob05g2G-Wpp4"
      },
      "source": [
        "# RandomForestClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fH2ME7YYWpp5"
      },
      "source": [
        "Реализуйте самостоятельно и оцените точность, как в примерах выше"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "e5mTDJG_Wpp5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9b0bf93-abb5-4819-80d9-97ce35ea5df4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+--------+--------------------+\n",
            "|prediction|Survived|            features|\n",
            "+----------+--------+--------------------+\n",
            "|       1.0|       0|[1.0,50.0,0.0,0.0...|\n",
            "|       0.0|       0|(9,[0,1,4,5],[1.0...|\n",
            "|       0.0|       0|[1.0,24.0,0.0,0.0...|\n",
            "|       0.0|       0|(9,[0,1,5,6],[1.0...|\n",
            "|       0.0|       0|(9,[0,1,5,6],[1.0...|\n",
            "+----------+--------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "\n",
        "rf = RandomForestClassifier(labelCol=\"Survived\", featuresCol=\"features\")\n",
        "rf_model = rf.fit(training_data)\n",
        "rf_prediction = rf_model.transform(test_data)\n",
        "\n",
        "rf_prediction.select(\"prediction\", \"Survived\", \"features\").show(5)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rf_accuracy = evaluator.evaluate(rf_prediction)\n",
        "print(\"DecisionTreeClassifier [Accuracy] = %g\"% (rf_accuracy))\n",
        "print(\"DecisionTreeClassifier [Error] = %g \" % (1.0 - rf_accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mPkPhOaq1EAC",
        "outputId": "945051c4-bac4-46b5-f28e-e28ea4d66b9b"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DecisionTreeClassifier [Accuracy] = 0.827586\n",
            "DecisionTreeClassifier [Error] = 0.172414 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "OLslRtOOWpp5"
      },
      "source": [
        "# Gradient-boosted tree classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AxCkpq1aWpp5"
      },
      "source": [
        "Реализуйте самостоятельно и оцените точность, как в примерах выше"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "8sF8i7YwWpp6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48feaf5b-08c3-4684-a1ae-f16247474cba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+--------+--------------------+\n",
            "|prediction|Survived|            features|\n",
            "+----------+--------+--------------------+\n",
            "|       1.0|       0|[1.0,50.0,0.0,0.0...|\n",
            "|       0.0|       0|(9,[0,1,4,5],[1.0...|\n",
            "|       0.0|       0|[1.0,24.0,0.0,0.0...|\n",
            "|       1.0|       0|(9,[0,1,5,6],[1.0...|\n",
            "|       1.0|       0|(9,[0,1,5,6],[1.0...|\n",
            "+----------+--------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.ml.classification import GBTClassifier\n",
        "\n",
        "gb = GBTClassifier(labelCol=\"Survived\", featuresCol=\"features\")\n",
        "gb_model = gb.fit(training_data)\n",
        "gb_prediction = gb_model.transform(test_data)\n",
        "\n",
        "gb_prediction.select(\"prediction\", \"Survived\", \"features\").show(5)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gb_accuracy = evaluator.evaluate(gb_prediction)\n",
        "print(\"DecisionTreeClassifier [Accuracy] = %g\"% (gb_accuracy))\n",
        "print(\"DecisionTreeClassifier [Error] = %g \" % (1.0 - gb_accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMJHQp1k1HTC",
        "outputId": "2f4f6cba-110d-4250-d413-550065750b45"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DecisionTreeClassifier [Accuracy] = 0.862069\n",
            "DecisionTreeClassifier [Error] = 0.137931 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "AC1j-bDYWpp6"
      },
      "source": [
        "# Save & Load Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "bqWorkQWWpp6"
      },
      "outputs": [],
      "source": [
        "# обученную модель мы можем сохранять. Сохраним модель RandomForest.\n",
        "rf_model.write().overwrite().save('rf_model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "nzgrGLIkWpp6",
        "outputId": "1aa7b892-e5ba-4cc3-cbfe-77cbedf58011",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyspark.ml.classification.RandomForestClassificationModel"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>pyspark.ml.classification.RandomForestClassificationModel</b><br/>def __init__(java_model: Optional[&#x27;JavaObject&#x27;]=None)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/pyspark/ml/classification.py</a>Model fitted by RandomForestClassifier.\n",
              "\n",
              ".. versionadded:: 1.4.0</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 2250);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "# Теперь модель загрузим. Для этого сначала модключим нужный класс\n",
        "from pyspark.ml.classification import RandomForestClassificationModel\n",
        "type(RandomForestClassificationModel.load('rf_model'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "ZD7hwefpWpp7"
      },
      "source": [
        "# Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "99fbFd8MWpp7"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.pipeline import PipelineModel\n",
        "\n",
        "# pipeline упрощает процесс внедрения ваших моделей в нужное окружение.\n",
        "\n",
        "# Перед тем, как модель обучить, мы уже выполнили какие-то преобразования данных.\n",
        "# Когда мы модель внедряем, нам нужно внедрять и все преобразования над данными.\n",
        "# Соответственно, появляется место для ошибок (человеческий фактор). Какую-то предобработку могут забыть сделать или сделать неправильно.\n",
        "# Пайплайны позволяют собрать вашу модель вместе с трансформациями."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "bdfnQzizWpp8"
      },
      "outputs": [],
      "source": [
        "titanic_df = spark.read.parquet('train.parquet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "ms7u4fAQWpp8",
        "outputId": "a5f1ef53-d850-44b9-fd3e-d1beb52550ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+------+------+----+-----+-----+-------+--------+-----------+-----+\n",
            "|Survived|Pclass|   Sex| Age|SibSp|Parch|   Fare|Embarked|Family_Size|Alone|\n",
            "+--------+------+------+----+-----+-----+-------+--------+-----------+-----+\n",
            "|       0|     3|  male|22.0|    1|    0|   7.25|       S|          1|    0|\n",
            "|       1|     1|female|38.0|    1|    0|71.2833|       C|          1|    0|\n",
            "|       1|     3|female|26.0|    0|    0|  7.925|       S|          0|    1|\n",
            "|       1|     1|female|35.0|    1|    0|   53.1|       S|          1|    0|\n",
            "|       0|     3|  male|35.0|    0|    0|   8.05|       S|          0|    1|\n",
            "|       0|     3|  male|30.0|    0|    0| 8.4583|       Q|          0|    1|\n",
            "|       0|     1|  male|54.0|    0|    0|51.8625|       S|          0|    1|\n",
            "|       0|     3|  male| 2.0|    3|    1| 21.075|       S|          4|    0|\n",
            "|       1|     3|female|27.0|    0|    2|11.1333|       S|          2|    0|\n",
            "|       1|     2|female|14.0|    1|    0|30.0708|       C|          1|    0|\n",
            "|       1|     3|female| 4.0|    1|    1|   16.7|       S|          2|    0|\n",
            "|       1|     1|female|58.0|    0|    0|  26.55|       S|          0|    1|\n",
            "|       0|     3|  male|20.0|    0|    0|   8.05|       S|          0|    1|\n",
            "|       0|     3|  male|39.0|    1|    5| 31.275|       S|          6|    0|\n",
            "|       0|     3|female|14.0|    0|    0| 7.8542|       S|          0|    1|\n",
            "|       1|     2|female|55.0|    0|    0|   16.0|       S|          0|    1|\n",
            "|       0|     3|  male| 2.0|    4|    1| 29.125|       Q|          5|    0|\n",
            "|       1|     2|  male|30.0|    0|    0|   13.0|       S|          0|    1|\n",
            "|       0|     3|female|31.0|    1|    0|   18.0|       S|          1|    0|\n",
            "|       1|     3|female|30.0|    0|    0|  7.225|       C|          0|    1|\n",
            "+--------+------+------+----+-----+-----+-------+--------+-----------+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "titanic_df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "000q1Vf6Wpp8"
      },
      "outputs": [],
      "source": [
        "train, test = titanic_df.randomSplit([0.8, 0.2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "7hIaynQbWpp9",
        "outputId": "7bab6f06-fe52-499a-c457-cddbbef9e64b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+------+------+----+-----+-----+-------+--------+-----------+-----+\n",
            "|Survived|Pclass|   Sex| Age|SibSp|Parch|   Fare|Embarked|Family_Size|Alone|\n",
            "+--------+------+------+----+-----+-----+-------+--------+-----------+-----+\n",
            "|       0|     1|female| 2.0|    1|    2| 151.55|       S|          3|    0|\n",
            "|       0|     1|female|25.0|    1|    2| 151.55|       S|          3|    0|\n",
            "|       0|     1|female|50.0|    0|    0|28.7125|       C|          0|    1|\n",
            "|       0|     1|  male|18.0|    1|    0|  108.9|       C|          1|    0|\n",
            "|       0|     1|  male|19.0|    1|    0|   53.1|       S|          1|    0|\n",
            "+--------+------+------+----+-----+-----+-------+--------+-----------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "train.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "LeaP_qpsWpqS"
      },
      "outputs": [],
      "source": [
        "indexer_sex = StringIndexer(inputCol=\"Sex\", outputCol=\"Sex_index\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "D8OEtn3FWpqS"
      },
      "outputs": [],
      "source": [
        "indexer_embarked = StringIndexer(inputCol=\"Embarked\", outputCol=\"Embarked_index\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "a4ujGKheWpqT"
      },
      "outputs": [],
      "source": [
        "feature = VectorAssembler(\n",
        "    inputCols=[\"Pclass\",\"Age\",\"SibSp\",\"Parch\",\"Fare\",\"Family_Size\",\"Embarked_index\",\"Sex_index\"],\n",
        "    outputCol=\"features\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "0BHKS7E9WpqT"
      },
      "outputs": [],
      "source": [
        "rf_classifier = RandomForestClassifier(labelCol=\"Survived\", featuresCol=\"features\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "UCb0OoOKWpqU"
      },
      "outputs": [],
      "source": [
        "pipeline = Pipeline(stages=[indexer_sex, indexer_embarked, feature, rf_classifier])\n",
        "# Определились с моделью созддаём Pipeline. Указываем массив из трансформаций, которые необходимо выполнить.\n",
        "# Собранный Pipeline является Estimator'ом, вызываем метод fit, из датафрейма (начального) в одно действие получается готовая модель."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "EnyRWQJHWpqU"
      },
      "outputs": [],
      "source": [
        "p_model = pipeline.fit(train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "trAzeLfrWpqU",
        "outputId": "73bb81ab-c86e-42b6-b0a8-b684bb166f66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyspark.ml.pipeline.PipelineModel"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>pyspark.ml.pipeline.PipelineModel</b><br/>def __init__(stages: List[Transformer])</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/pyspark/ml/pipeline.py</a>Represents a compiled pipeline with transformers and fitted models.\n",
              "\n",
              ".. versionadded:: 1.3.0</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 290);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "type(p_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "XQ3DQOD-WpqV"
      },
      "outputs": [],
      "source": [
        "p_model.write().overwrite().save('p_model')\n",
        "# сохраним модель с перезаписью."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "2ItP6vjsWpqV"
      },
      "outputs": [],
      "source": [
        "model = PipelineModel.load('p_model')\n",
        "# Загрузим модель."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "K3eMaROCWpqW"
      },
      "outputs": [],
      "source": [
        "prediction = p_model.transform(test)\n",
        "# применим модель, вызовем метод transrorm, применим его к выборке test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "D7WVK69WWpqW",
        "outputId": "776d9c84-0402-4f1b-e667-52d24594b4ca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+------+----+----+-----+-----+--------+--------+-----------+-----+\n",
            "|Survived|Pclass| Sex| Age|SibSp|Parch|    Fare|Embarked|Family_Size|Alone|\n",
            "+--------+------+----+----+-----+-----+--------+--------+-----------+-----+\n",
            "|       0|     1|male|19.0|    3|    2|   263.0|       S|          5|    0|\n",
            "|       0|     1|male|22.0|    0|    0|135.6333|       C|          0|    1|\n",
            "|       0|     1|male|24.0|    0|    1|247.5208|       C|          1|    0|\n",
            "|       0|     1|male|30.0|    0|    0|    35.0|       S|          0|    1|\n",
            "|       0|     1|male|30.0|    0|    0| 227.525|       C|          0|    1|\n",
            "+--------+------+----+----+-----+-----+--------+--------+-----------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "test.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "G3tWZ0CQWpqW",
        "outputId": "daf70276-9231-49bc-d781-3e65b411cc03",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+----+-----+-----+--------+-----------+--------------+---------+----------+\n",
            "|Pclass| Age|SibSp|Parch|    Fare|Family_Size|Embarked_index|Sex_index|prediction|\n",
            "+------+----+-----+-----+--------+-----------+--------------+---------+----------+\n",
            "|     1|19.0|    3|    2|   263.0|          5|           0.0|      0.0|       0.0|\n",
            "|     1|22.0|    0|    0|135.6333|          0|           1.0|      0.0|       0.0|\n",
            "|     1|24.0|    0|    1|247.5208|          1|           1.0|      0.0|       0.0|\n",
            "|     1|30.0|    0|    0|    35.0|          0|           0.0|      0.0|       0.0|\n",
            "|     1|30.0|    0|    0| 227.525|          0|           1.0|      0.0|       1.0|\n",
            "+------+----+-----+-----+--------+-----------+--------------+---------+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "prediction.select([\"Pclass\",\"Age\",\"SibSp\",\"Parch\",\"Fare\",\"Family_Size\",\"Embarked_index\",\"Sex_index\",\"prediction\"]).show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "k-ffaIDzWpqX"
      },
      "outputs": [],
      "source": [
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"Survived\", predictionCol=\"prediction\", metricName=\"accuracy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "5YWNf0f7WpqX",
        "outputId": "9273c720-81a4-4f03-f13c-e77f1582d81a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pipeline model [Accuracy] = 0.892655\n",
            "Pipeline model [Error] = 0.107345 \n"
          ]
        }
      ],
      "source": [
        "p_accuracy = evaluator.evaluate(prediction)\n",
        "print(\"Pipeline model [Accuracy] = %g\"% (p_accuracy))\n",
        "print(\"Pipeline model [Error] = %g \" % (1.0 - p_accuracy))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QpjUJ0FLWpqY"
      },
      "source": [
        "Сделайте самостоятельно Pipeline для Градиентного Бустинга, проверьте точность на тестовой выборке."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gb_classifier = GBTClassifier(labelCol=\"Survived\", featuresCol=\"features\")\n",
        "\n",
        "pipeline = Pipeline(stages=[indexer_sex, indexer_embarked, feature, gb_classifier])\n",
        "\n",
        "p_model = pipeline.fit(train)\n",
        "\n",
        "prediction = p_model.transform(test)\n",
        "\n",
        "p_accuracy = evaluator.evaluate(prediction)\n",
        "print(\"Pipeline model [Accuracy] = %g\"% (p_accuracy))\n",
        "print(\"Pipeline model [Error] = %g \" % (1.0 - p_accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ji-ZvYqW1Xd3",
        "outputId": "fea42bd7-be77-4ff2-95ab-50b96ddb181b"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pipeline model [Accuracy] = 0.847458\n",
            "Pipeline model [Error] = 0.152542 \n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}